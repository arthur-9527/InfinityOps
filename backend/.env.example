# Server Configuration
PORT=3001
WS_PORT=3002
NODE_ENV=development

# AI Service Configuration
AI_PROVIDER=ollama  # Options: openai, anthropic, ollama
AI_MODEL=gemma3:latest     # Model name based on provider
AI_API_KEY=         # Required for OpenAI and Anthropic
AI_BASE_URL=http://localhost:11434/v1       # Optional: Custom API base URL
AI_MAX_TOKENS=2000  # Maximum tokens for AI responses

OLLAMA_API_URL=http://localhost:11434/v1
OLLAMA_DEFAULT_MODEL=gemma3:latest
OLLAMA_CONTEXT_WINDOW=4096
OLLAMA_TIMEOUT=60000
OLLAMA_MAX_TOKENS=2048
OLLAMA_TEMPERATURE=0.7

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=Aa123578964
REDIS_DB=0



# Logging
LOG_LEVEL=debug      # Options: debug, info, warn, error
LOG_FILE=logs/app.log

# 意图分析 AI 配置
INTENT_AI_PROVIDER=ollama  # 可选: ollama, openai, anthropic
INTENT_AI_MODEL=gemma3:latest  # 根据提供商选择合适的模型

# 跳过命令配置
SKIP_COMMANDS=ls,cd,pwd

# 结果分析 AI 配置
RESULT_AI_PROVIDER=ollama  # 可选: ollama, openai, anthropic
RESULT_AI_MODEL=qwq:latest  # 根据提供商选择合适的模型


